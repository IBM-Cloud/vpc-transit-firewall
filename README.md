# Firewall appliances in a transit VPC
This is the companion repository for the blog post [VPC Transit Firewall](todo).  Terraform is used in this repository to depoloy the following architecture:

![intro](./images/firewall-intro.png){: class="center"}

## Prerequisites

Before continuing you must satisfy the following prereequisites.
- Permissions to create resources including: VPC and instances, Transit Gateway,Â 
- [Shell with ibmcloud cli and terraform](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials)
- Follow the instructions to satisfy the [Prerequisites for NLB with routing mode](https://cloud.ibm.com/docs/vpc?topic=vpc-nlb-vnf&interface=ui)
- IAM policy to create instances with network interfaces that allow spoofing. [See about IP spoofing checks](https://cloud.ibm.com/docs/vpc?topic=vpc-ip-spoofing-about):
```
ibmcloud iam user-policy-create YOUR_USER_EMAIL_ADDRESS --roles "IP Spoofing Operator" --service-name is
```

## TLDR;

Create the vpcs, firewall, routes and transit bastion:
```
cp template.local.env local.env
# make any adjustments
vi local.env
source local.env
terraform init
terraform apply
```

Create the spoke instances to generate load:
```
cd load_tf
terraform init
terraform apply
```

By default one availability zone with one firewall is created which makes it easier to explore and test.

NOTE: The output generated in my example are shown below.  Your IP values will be different, adjust the steps accordingly.

Initial terraform apply output:

```
spokes = {
  "0" = {
    "vpc_id" = "r006-1897fe56-5b6f-487d-8e91-a381f16ca74d"
    "zones" = {
      "0" = {
        "routing_table_id" = "r006-70610d62-448a-4ed6-aee9-144b50f72952"
        "subnet_id" = "0717-c8664a11-d65a-4a62-8787-455e4ce53349"
        "zone" = "us-south-1"
      }
    }
  }
  "1" = {
    "vpc_id" = "r006-7f2903a3-045c-417e-9fc4-5ee45e3d6f69"
    "zones" = {
      "0" = {
        "routing_table_id" = "r006-81ffe1c9-6fd9-4929-8479-e79eae611546"
        "subnet_id" = "0717-7b0175a1-1312-4d8d-af8c-f2b12db4e25e"
        "zone" = "us-south-1"
      }
    }
  }
}
transit_zones = {
  "0" = {
    "bastion_floating_ip_address" = "52.118.184.49"
    "bastion_primary_ipv4_address" = "10.8.0.4"
    "firewalls" = {
      "0" = {
        "floating_ip_address" = "52.116.138.80"
        "primary_ipv4_address" = "10.8.0.196"
      }
    }
    "name" = "vpcfw-transit-1"
    "next_hop" = "10.8.0.198"
    "subnet_available0_id" = "0717-0c87409e-a6b4-447d-93ed-acbff880ec9a"
    "vpc_id" = "r006-1aadb726-870e-4a8c-9cca-b30f7042ce58"
    "zone" = "us-south-1"
  }
}
```

load_tf output:

```
spoke_instances = [
  {
    "jump_floating_ip" = "52.118.184.49"
    "name" = "vpcfw-load-0-us-south-1"
    "primary_ipv4_address" = "10.8.1.4"
    "spoke_key" = "0"
    "ssh" = "ssh -J root@52.118.184.49 root@10.8.1.4"
    "zone" = "us-south-1"
    "zone_key" = "0"
  },
  {
    "jump_floating_ip" = "52.118.184.49"
    "name" = "vpcfw-load-1-us-south-1"
    "primary_ipv4_address" = "10.8.2.4"
    "spoke_key" = "1"
    "ssh" = "ssh -J root@52.118.184.49 root@10.8.2.4"
    "zone" = "us-south-1"
    "zone_key" = "0"
  },
]
```


It is interesting to inspect the routing table for one of the spokes.  Using the vpc_id and the routing_table_id.  Notice that all traffic (0.0.0.0/0) is routed to the Network Load Balancer, NLB.  The NLB forwards that to the firewall, with one exception for the bastion (discussed in [Spoke routing[(#spoke-routing) later):

```
$ ibmcloud is vpc-routing-table-routes r006-7f2903a3-045c-417e-9fc4-5ee45e3d6f69 r006-81ffe1c9-6fd9-4929-8479-e79eae611546
Listing routes for routing table r006-81ffe1c9-6fd9-4929-8479-e79eae611546 of vpc r006-7f2903a3-045c-417e-9fc4-5ee45e3d6f69 under account Powell Quiring's Account as user pquiring@us.ibm.com...
ID                                          Name                                       Action     Status   Destination   Next hop     Zone
r006-bc7d6518-3d92-47a0-872f-761a74c4bd18   vpcfw-spoke-1-us-south-1-transit-bastion   delegate   stable   10.8.0.4/32   0.0.0.0      us-south-1
r006-e4839bad-b484-471b-aa3f-3fa0fb721577   vpcfw-spoke-1-us-south-1                   deliver    stable   0.0.0.0/0     10.8.0.198   us-south-1
```


Be ready to set up a couple of ssh sessions.  In one terminal ssh to the firewall.  Check out the iptables that confiure the firewall:
```
$ ssh root@52.116.138.80
....
root@vpcfw-transit-1-firewall-0:~# iptables-save
# Generated by iptables-save v1.8.4 on Tue Jun 21 15:26:48 2022
*nat
:PREROUTING ACCEPT [711:39575]
:INPUT ACCEPT [641:34107]
:OUTPUT ACCEPT [14:1814]
:POSTROUTING ACCEPT [71:6502]
-A POSTROUTING -s 10.8.0.0/16 -d 10.8.0.0/16 -p tcp -j ACCEPT
-A POSTROUTING -s 10.8.0.0/16 -p tcp -j SNAT --to-source 10.8.0.196
COMMIT
# Completed on Tue Jun 21 15:26:48 2022
# Generated by iptables-save v1.8.4 on Tue Jun 21 15:26:48 2022
*filter
:INPUT ACCEPT [2699:283426]
:FORWARD ACCEPT [16040:265456293]
:OUTPUT ACCEPT [2330:407614]
COMMIT
# Completed on Tue Jun 21 15:26:48 2022
```

The `*filter` section has a `:FORWARD ACCEPT` to allow all packets that are recieved and not addressed to this instance to be forwarded to the destination.  The traffic from the spokes will be forwarded towards the destination.  Each packet has a source address of the sender since a NLB is configured with [Direct Server Return](https://cloud.ibm.com/docs/vpc?topic=vpc-network-load-balancers).

The `*nat` section will be covered in more detail later and can be ignored for now.

On the firewall capture all of the packets to/from the spoke 1 instance (spoke_key == 1):

```
root@vpcfw-transit-1-firewall-0:~# tcpdump -n host 10.8.2.4
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on ens3, link-type EN10MB (Ethernet), capture size 262144 bytes
```

In a different terminal ssh to the spoke 0 intance (spoke_key == 0), There is a handy ssh command that uses the transit bastion as a jump server.  Then curl to the spoke 1 instance:
```
$ ssh -J root@52.118.184.49 root@10.8.1.4
...
root@vpcfw-load-0-us-south-1-private:~# curl 10.8.2.4/instance
vpcfw-load-1-us-south-1-private
```

You should have noticed a burst of traffic on the firewalls tcpdump.  There is a pair for each packet, the first is when the firewall received the packet and the second is when the firewall FORWARDed the packet as described by iptables-save.  Forwarding is also effecting the return trip.  Here are the first four packets:
```
root@vpcfw-transit-1-firewall-0:~# tcpdump -n host 10.8.2.4
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on ens3, link-type EN10MB (Ethernet), capture size 262144 bytes
15:36:01.025173 IP 10.8.1.4.38874 > 10.8.2.4.80: Flags [S], seq 1034822911, win 64240, options [mss 1460,sackOK,TS val 359570064 ecr 0,nop,wscale 7], length 0
15:36:01.025243 IP 10.8.1.4.38874 > 10.8.2.4.80: Flags [S], seq 1034822911, win 64240, options [mss 1460,sackOK,TS val 359570064 ecr 0,nop,wscale 7], length 0
15:36:01.026175 IP 10.8.2.4.80 > 10.8.1.4.38874: Flags [S.], seq 4014523402, ack 1034822912, win 65160, options [mss 1460,sackOK,TS val 1959068290 ecr 359570064,nop,wscale 7], length 0
15:36:01.026186 IP 10.8.2.4.80 > 10.8.1.4.38874: Flags [S.], seq 4014523402, ack 1034822912, win 65160, options [mss 1460,sackOK,TS val 1959068290 ecr 359570064,nop,wscale 7], length 0
```
## Configuration
There are a few terraform [variables](./variables.tf) that can be used to tune things up.  Here are a couple to look at:

- firewall_replicas - default 1, if your firewall supports multiple instances then scaling them could hep with performance and availability.
- firewall_lb - default true, if you only have a single firewall there is no reason to use a NLB, lets set this to false and try again:

```
vi local.env; # uncomment export TF_VAR_firewall_lb=false
source local.env
terraform apply
```

The NLB will be deleted and the spoke routing tables will be configured to forward directly to the firewall.  Terraform output states the next_hop is the ip address of the firewall, 10.8.0.196 below:
```
transit_zones = {
  "0" = {
    "bastion_floating_ip_address" = "52.118.184.49"
    "bastion_primary_ipv4_address" = "10.8.0.4"
    "firewalls" = {
      "0" = {
        "floating_ip_address" = "52.116.138.80"
        "primary_ipv4_address" = "10.8.0.196"
      }
    }
    "name" = "vpcfw-transit-1"
    "next_hop" = "10.8.0.196"
    "subnet_available0_id" = "0717-0c87409e-a6b4-447d-93ed-acbff880ec9a"
    "vpc_id" = "r006-1aadb726-870e-4a8c-9cca-b30f7042ce58"
    "zone" = "us-south-1"
  }
}
```

Confirm this in the spoke route tables has changed as well:
```
$ is vpc-routing-table-routes r006-7f2903a3-045c-417e-9fc4-5ee45e3d6f69 r006-81ffe1c9-6fd9-4929-8479-e79eae611546
Listing routes for routing table r006-81ffe1c9-6fd9-4929-8479-e79eae611546 of vpc r006-7f2903a3-045c-417e-9fc4-5ee45e3d6f69 under account Powell Quiring's Account as user pquiring@us.ibm.com...
ID                                          Name                                       Action     Status   Destination   Next hop     Zone
r006-bc7d6518-3d92-47a0-872f-761a74c4bd18   vpcfw-spoke-1-us-south-1-transit-bastion   delegate   stable   10.8.0.4/32   0.0.0.0      us-south-1
r006-80a77bff-33d3-4567-b212-fb86b6551c38   vpcfw-spoke-1-us-south-1                   deliver    stable   0.0.0.0/0     10.8.0.196   us-south-1
```

## spoke routing detail
Each spoke has an egress routing table with two entries.  Why is the second entry required to allow the transit bastion to be used?
```
ID                                          Name                                       Action     Status   Destination   Next hop     Zone
r006-bc7d6518-3d92-47a0-872f-761a74c4bd18   vpcfw-spoke-1-us-south-1-transit-bastion   delegate   stable   10.8.0.4/32   0.0.0.0      us-south-1
```

Without this routing table entry in the egress route table for the spoke subnet the ssh traffic would flow as shown in the red line:

![intro](./images/firewall-bastion-fail.png){: class="center"}


Although the data path is complete it is not symetric

## iptables
If you are not interested in th
### Transit firewall via iptables
## Spoke
A source network address translation, SNAT, is required in the firewall to route traffic over the floating ip that is attached to the firewall.  The NLB has Direct Server Retuirn, DSR, meaning the source address in the packet is the originating instance in the spoke. The server in the cloud is found with
```
iptables-restore <<'EOF'
*filter
:INPUT ACCEPT 
:FORWARD ACCEPT
:OUTPUT ACCEPT
COMMIT

# nat allows the spokes access to the internet
*nat
:PREROUTING ACCEPT
:INPUT ACCEPT
:OUTPUT ACCEPT
:POSTROUTING ACCEPT
-A POSTROUTING -d 10.8.0.0/18 -p tcp -j ACCEPT
-A POSTROUTING -s 10.8.1.0/24 -p tcp -j SNAT --to-source 10.8.0.198
-A POSTROUTING -s 10.8.2.0/24 -p tcp -j SNAT --to-source 10.8.0.198
COMMIT
EOF

# second
iptables-restore <<'EOF'
*filter
:INPUT ACCEPT 
:FORWARD ACCEPT
:OUTPUT ACCEPT
COMMIT

*nat
:PREROUTING ACCEPT
:INPUT ACCEPT
:OUTPUT ACCEPT
:POSTROUTING ACCEPT
-A POSTROUTING -d 10.8.0.0/18 -p tcp -j ACCEPT
-A POSTROUTING -s 10.8.1.0/24 -p tcp -j SNAT --to-source 10.8.0.196
-A POSTROUTING -s 10.8.2.0/24 -p tcp -j SNAT --to-source 10.8.0.196
COMMIT
EOF
```

```
# set
sysctl -w net.ipv4.ip_forward=1
# print
sysctl net.ipv4.ip_forward


apt install -y ntpsec-ntpdate
```